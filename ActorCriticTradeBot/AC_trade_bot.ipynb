{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AC_trade_bot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nautiism/fin_papers_done/blob/master/ActorCriticTradeBot/AC_trade_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50gFIoT5EdB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84d22e1b-9975-4517-dea9-4c3438510057"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVgINIhEhDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.init as init\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7TtAKwgEdB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.LSTMCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRUCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MbWSTx8EdCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TradeEnv():\n",
        "    def __init__(self,share_count,start_cash,sbin,rel,cus=0,brokerage=0.1):\n",
        "        self.broker = brokerage\n",
        "        self.inaction_penalty = 0\n",
        "        self.so = sbin['Open'];self.sc = sbin['Close'];\n",
        "        self.ro = rel['Open'];self.rc = rel['Close']\n",
        "        \n",
        "        self.startS = cus\n",
        "        self.cus = cus\n",
        "        self.ss = 1 \n",
        "        self.epi_length = len(self.so)\n",
        "        \n",
        "        self.start_cash = max(int(np.random.normal(start_cash['mu'],start_cash['sig'])),0)\n",
        "\n",
        "        self.state = {}\n",
        "        self.state['sbin_share_count']= max(int(np.random.normal(share_count['sbin']['mu'],share_count['sbin']['sig'])),0)\n",
        "        self.state['rel_share_count']= max(int(np.random.normal(share_count['rel']['mu'],share_count['rel']['sig'])),0)\n",
        "        self.state['liquidity'] = self.start_cash \n",
        "        self.align()\n",
        "        self.init_portfolio = self.state['portfolio_val']\n",
        "        \n",
        "        self.end = False\n",
        "        \n",
        "    def align(self):\n",
        "        self.state['portfolio_val'] = self.state['sbin_share_count'] * self.sc[self.cus] + self.state['rel_share_count'] * self.rc[self.cus]\n",
        "        self.state['sbin_open'] = self.so[self.cus]\n",
        "        self.state['rel_open'] = self.ro[self.cus]\n",
        "        self.state['sbin_ma_5'] = self.so[self.cus] if self.cus < 5 else self.so[self.cus-5:self.cus].mean() \n",
        "        self.state['rel_ma_5'] = self.ro[self.cus] if self.cus < 5 else self.ro[self.cus-5:self.cus].mean()\n",
        "        \n",
        "    def gain(self):\n",
        "        return self.state['portfolio_val']-self.init_porfolio\n",
        "    \n",
        "    def t_remain(self):\n",
        "        return self.epi_length-(self.cus-self.startS) \n",
        "        \n",
        "    def step(self,a):\n",
        "        quant = 1\n",
        "        bonus = 0\n",
        "        if self.cus > self.epi_length:\n",
        "            if self.state['sbin_share_count'] and self.state['rel_share_count']:\n",
        "                bonus = 1\n",
        "            return self.state.values(),self.state['portfolio_val']+bonus+self.gain(),True\n",
        "        \n",
        "        if a==0:\n",
        "            #buy sbin\n",
        "            if quant*self.so[self.cus] > self.state['liquidity']:\n",
        "                self.align()\n",
        "                return self.state.values(),-1*self.t_remain()+self.gain()/2,True\n",
        "            else:\n",
        "                self.state['sbin_share_count'] += quant\n",
        "                self.state['liquidity'] -= quant*self.so[self.cus]*(1+self.broker)\n",
        "                self.align()\n",
        "                return self.state.values(),self.inaction_penalty-1*self.t_remain()+self.gain(),False\n",
        "        elif a==1:\n",
        "            #sell sbin\n",
        "            if quant > self.state['sbin_share_count']:\n",
        "                self.align()\n",
        "                return self.state.values(),-1*self.t_remain()+self.gain()/2,True\n",
        "            else:\n",
        "                self.state['sbin_share_count']-=quant\n",
        "                self.state['liquidity'] += quant*self.so[self.cus]*(1-self.broker)\n",
        "                self.align()\n",
        "                return self.state.values(),self.inaction_penalty-1*self.t_remain()+self.gain(),False\n",
        "        elif a==2:\n",
        "            return self.state.values(),-1*self.inaction_penalty-1*self.t_remain()+self.gain(),False\n",
        "        elif a==3:\n",
        "            #buy rel\n",
        "            if quant*self.ro[self.cus] > self.state['liquidity']:\n",
        "                self.align()\n",
        "                return self.state.values(),-1*self.t_remain()+self.gain()/2,True\n",
        "            else:\n",
        "                self.state['rel_share_count'] += quant\n",
        "                self.state['liquidity'] -= quant*self.ro[self.cus]*(1+self.broker)\n",
        "                self.align()\n",
        "                return self.state.values(),self.inaction_penalty-1*self.t_remain()+self.gain(),False\n",
        "        elif a==4:\n",
        "            #sell sbin\n",
        "            if quant > self.state['rel_share_count']:\n",
        "                self.align()\n",
        "                return self.state.values(),-1*self.t_remain()+self.gain()/2,True\n",
        "            else:\n",
        "                self.state['sbin_share_count']-=quant\n",
        "                self.state['liquidity'] += quant*self.ro[self.cus]*(1-self.broker)\n",
        "                self.align()\n",
        "                return self.state.values(),self.inaction_penalty-1*self.t_remain()+self.gain(),False\n",
        "        \n",
        "    def reset(self):\n",
        "        self.cus = self.ss\n",
        "        self.epi_length = len(self.so)\n",
        "        self.start_cash = max(int(np.random.normal(start_cash['mu'],start_cash['sig'])),0)\n",
        "        self.state = {}\n",
        "        self.state['sbin_share_count']= max(int(np.random.normal(share_count['sbin']['mu'],share_count['sbin']['sig'])),0)\n",
        "        self.state['rel_share_count']= max(int(np.random.normal(share_count['rel']['mu'],share_count['rel']['sig'])),0)\n",
        "        self.state['liquidity'] = self.start_cash \n",
        "        self.align()\n",
        "        self.init_porfolio = self.state['portfolio_val']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYw7lviEdCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        \n",
        "        self.input_layer = nn.Linear(8, 128)\n",
        "        self.hidden_1 = nn.Linear(128, 128)\n",
        "        self.hidden_2 = nn.Linear(32,31)\n",
        "        self.hidden_state = torch.zeros(2,1,32).cuda()\n",
        "        self.rnn = nn.GRU(128, 32, 2)\n",
        "        \n",
        "        self.action_layer = nn.Linear(31, 5)\n",
        "        self.value_layer = nn.Linear(31, 1)\n",
        "          \n",
        "        self.logprobs = []\n",
        "        self.state_values = []\n",
        "        self.rewards = []\n",
        "        self.apply(weight_init)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.FloatTensor(list(x)).cuda()\n",
        "        x = self.input_layer(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = torch.tanh(self.hidden_1(x))\n",
        "        x, self.hidden_state = self.rnn(x.view(1,-1,128), self.hidden_state.data)\n",
        "        x = F.relu(self.hidden_2(x.squeeze()))\n",
        "        action_scores = self.action_layer(x)\n",
        "        state_value = self.value_layer(x)\n",
        "        action_probs = F.softmax(action_scores, dim=-1)\n",
        "        return action_probs,state_value \n",
        "    \n",
        "    def calculateLoss(self, gamma=0.99):\n",
        "        rewards = []\n",
        "        dis_reward = 0\n",
        "        for reward in self.rewards[::-1]:\n",
        "            dis_reward = reward + gamma * dis_reward\n",
        "            rewards.insert(0, dis_reward)\n",
        "        \n",
        "        rewards = torch.tensor(rewards).cuda()\n",
        "        if rewards.shape[0]==1:\n",
        "          rewards = (rewards - rewards.mean())\n",
        "        else:\n",
        "          rewards = (rewards - rewards.mean()) / (rewards.std(False))\n",
        "        \n",
        "        loss = torch.Tensor([0]).cuda()\n",
        "        for logprob, value, reward in zip(self.logprobs, self.state_values, rewards):\n",
        "            advantage = reward  - value\n",
        "            action_loss = -logprob * advantage\n",
        "            value_loss = F.smooth_l1_loss(value, reward)\n",
        "            loss += (action_loss + value_loss)\n",
        "        return loss\n",
        "    \n",
        "    def clearMemory(self):\n",
        "        del self.logprobs[:]\n",
        "        del self.state_values[:]\n",
        "        del self.rewards[:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbRITs0YEdCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sbi = pd.read_csv('./drive/My Drive/reinforce/sbi.csv')\n",
        "rel = pd.read_csv('./drive/My Drive/reinforce/rel.csv')\n",
        "\n",
        "share_count = {'sbin':{'mu':100,'sig':10},\n",
        "               'rel':{'mu':100,'sig':10}}\n",
        "start_cash = {'mu':1000,'sig':100}\n",
        "TE = TradeEnv(share_count,start_cash,sbi,rel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqLCxAN0EdCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bf299eae-a3d7-4854-ebd8-a75bb7805b0b"
      },
      "source": [
        "episodes = 100000\n",
        "total_profits = 0\n",
        "ac = ActorCritic().cuda()\n",
        "opt = optim.Adam(ac.parameters(), lr=3e-4)\n",
        "\n",
        "for j in range(episodes):\n",
        "    TE.reset()\n",
        "    opt.zero_grad()\n",
        "    state = list(TE.state.values())\n",
        "    for i in range(0,TE.epi_length  + 1):\n",
        "        actions,state_value = ac(state)\n",
        "        action_distribution = Categorical(actions)\n",
        "        action = action_distribution.sample()\n",
        "        ac.logprobs.append(action_distribution.log_prob(action))\n",
        "        ac.state_values.append(state_value)\n",
        "        state, reward, done = TE.step(action)\n",
        "        ac.rewards.append(reward)\n",
        "        if done:\n",
        "            break\n",
        "    loss = ac.calculateLoss()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    ac.clearMemory()\n",
        "total_profits += (TE.state['portfolio_val'] - TE.init_portfolio) /  TE.init_portfolio\n",
        "    \n",
        "print(\"Avg % profit per game: {}\".format(total_profits / episodes))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg % profit per game: -1.1426390524650747e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYgdDGRcsZ_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.FloatTensor([2.00,3.43,5.434,45.334]).shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}